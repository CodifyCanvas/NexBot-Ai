"use server";

import { GoogleGenAI } from "@google/genai";

const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY! });

export async function generateGeminiResponse(
  prompt: string,
  chatHistory: { message: string; sender: "user" | "bot" }[] = []
): Promise<string> {
  try {
    // Build the conversation history properly by adding previous messages
    const conversationHistory = chatHistory
      .map((entry) => `${entry.sender === "user" ? "User" : "Bot"}: ${entry.message}`)
      .join("\n");

    // Construct the prompt that will be passed to Gemini
    const fullPrompt = `${conversationHistory}\nUser: ${prompt}\nBot:`;

    console.log("Full prompt sent to Gemini:", fullPrompt);  // Debugging output to see how the prompt looks

    // Call the Gemini API to generate the response
    const response = await ai.models.generateContent({
      model: "gemini-2.0-flash", // Use the model suited for your case
      contents: [
        {
          role: "user",
          parts: [{ text: fullPrompt }],
        },
      ],
      config: {
        systemInstruction: `You are an AI assistant named Nexbot.
                            If someone asks, "What is your name?" or similar, respond with: "My name is Nexbot."
                            If someone asks, "Who created you?" or similar, respond with: "I was created by Shahzaib Awan for an AI chatbot project."
                            If someone asks, "who is shahzaib awan?" or similar, respond with: "He is a Full-Stack Developer."
                            Remain helpful, professional, and concise in all your responses.`,
      },
    });

    // Return the response text generated by Gemini
    return response.text || "No response from Gemini.";
  } catch (error) {
    console.error("Gemini API error:", error);
    throw new Error("Failed to generate response from Gemini.");
  }
}
